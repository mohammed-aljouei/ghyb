{"ast":null,"code":"var _s = $RefreshSig$();\n\nimport { useState, useEffect, useRef } from 'react';\nimport Hark from 'hark';\nimport { startRecording, stopRecording } from './recorderHelpers'; // https://cloud.google.com/speech-to-text/docs/reference/rest/v1/RecognitionConfig\n\nconst isEdgeChromium = navigator.userAgent.indexOf('Edg/') !== -1;\nconst AudioContext = window.AudioContext || window.webkitAudioContext;\nconst SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\nlet recognition; // Set recognition back to null for brave browser due to promise resolving\n// after the conditional on line 31\n\nif (navigator.brave) {\n  navigator.brave.isBrave().then(bool => {\n    if (bool) recognition = null;\n  });\n} // Chromium browsers will have the SpeechRecognition method\n// but do not implement the functionality due to google wanting ðŸ’°\n// this covers new Edge and line 22 covers Brave, the two most popular non-chrome chromium browsers\n\n\nif (!isEdgeChromium && SpeechRecognition) {\n  recognition = new SpeechRecognition();\n}\n\nexport default function useSpeechToText({\n  continuous,\n  crossBrowser,\n  googleApiKey,\n  googleCloudRecognitionConfig,\n  onStartSpeaking,\n  onStoppedSpeaking,\n  speechRecognitionProperties,\n  timeout,\n  useOnlyGoogleCloud = true\n}) {\n  _s();\n\n  const [isRecording, setIsRecording] = useState(false);\n  const audioContextRef = useRef();\n  const [results, setResults] = useState([]);\n  const [interimResult, setInterimResult] = useState();\n  const [error, setError] = useState('');\n  const timeoutId = useRef();\n  const mediaStream = useRef();\n  useEffect(() => {\n    var _navigator, _navigator$mediaDevic;\n\n    if (!crossBrowser && !recognition) {\n      setError('Speech Recognition API is only available on Chrome');\n    }\n\n    if (!((_navigator = navigator) === null || _navigator === void 0 ? void 0 : (_navigator$mediaDevic = _navigator.mediaDevices) === null || _navigator$mediaDevic === void 0 ? void 0 : _navigator$mediaDevic.getUserMedia)) {\n      setError('getUserMedia is not supported on this device/browser :(');\n    }\n\n    if ((crossBrowser || useOnlyGoogleCloud) && !googleApiKey) {\n      console.error('No google cloud API key was passed, google API will not be able to process speech');\n    }\n\n    if (!audioContextRef.current) {\n      audioContextRef.current = new AudioContext();\n    }\n  }, []); // Chrome Speech Recognition API:\n  // Only supported on Chrome browsers\n\n  const chromeSpeechRecognition = () => {\n    if (recognition) {\n      // Continuous recording after stopped speaking event\n      if (continuous) recognition.continuous = true;\n      const {\n        grammars,\n        interimResults,\n        lang,\n        maxAlternatives\n      } = speechRecognitionProperties || {};\n      if (grammars) recognition.grammars = grammars;\n      if (lang) recognition.lang = lang;\n      recognition.interimResults = interimResults || false;\n      recognition.maxAlternatives = maxAlternatives || 1; // start recognition\n\n      recognition.start(); // speech successfully translated into text\n\n      recognition.onresult = e => {\n        const result = e.results[e.results.length - 1];\n        const {\n          transcript\n        } = result[0]; // Allows for realtime speech result UI feedback\n\n        if (interimResults) {\n          if (result.isFinal) {\n            setInterimResult(undefined);\n            setResults(prevResults => [...prevResults, transcript]);\n          } else {\n            let concatTranscripts = ''; // If continuous: e.results will include previous speech results: need to start loop at the current event resultIndex for proper concatenation\n\n            for (let i = e.resultIndex; i < e.results.length; i++) {\n              concatTranscripts += e.results[i][0].transcript;\n            }\n\n            setInterimResult(concatTranscripts);\n          }\n        } else {\n          setResults(prevResults => [...prevResults, transcript]);\n        }\n      };\n\n      recognition.onaudiostart = () => setIsRecording(true); // Audio stopped recording or timed out.\n      // Chrome speech auto times-out if no speech after a while\n\n\n      recognition.onend = () => {\n        setIsRecording(false);\n      };\n    }\n  };\n\n  const startSpeechToText = async () => {\n    var _audioContextRef$curr;\n\n    if (!useOnlyGoogleCloud && recognition) {\n      chromeSpeechRecognition();\n      return;\n    }\n\n    if (!crossBrowser && !useOnlyGoogleCloud) {\n      return;\n    } // Resume audio context due to google auto play policy\n    // https://developers.google.com/web/updates/2017/09/autoplay-policy-changes#webaudio\n\n\n    if (((_audioContextRef$curr = audioContextRef.current) === null || _audioContextRef$curr === void 0 ? void 0 : _audioContextRef$curr.state) === 'suspended') {\n      var _audioContextRef$curr2;\n\n      (_audioContextRef$curr2 = audioContextRef.current) === null || _audioContextRef$curr2 === void 0 ? void 0 : _audioContextRef$curr2.resume();\n    }\n\n    const stream = await startRecording({\n      errHandler: () => setError('Microphone permission was denied'),\n      audioContext: audioContextRef.current\n    }); // Stop recording if timeout\n\n    if (timeout) {\n      handleRecordingTimeout();\n    } // stop previous mediaStream track if exists\n\n\n    if (mediaStream.current) {\n      mediaStream.current.getAudioTracks()[0].stop();\n    } // Clones stream to fix hark bug on Safari\n\n\n    mediaStream.current = stream.clone();\n    const speechEvents = Hark(mediaStream.current, {\n      audioContext: audioContextRef.current\n    });\n    speechEvents.on('speaking', () => {\n      if (onStartSpeaking) onStartSpeaking(); // Clear previous recording timeout on every speech event\n\n      clearTimeout(timeoutId.current);\n    });\n    speechEvents.on('stopped_speaking', () => {\n      var _mediaStream$current;\n\n      if (onStoppedSpeaking) onStoppedSpeaking();\n      setIsRecording(false);\n      (_mediaStream$current = mediaStream.current) === null || _mediaStream$current === void 0 ? void 0 : _mediaStream$current.getAudioTracks()[0].stop(); // Stops current recording and sends audio string to google cloud.\n      // recording will start again after google cloud api\n      // call if `continuous` prop is true. Until the api result\n      // returns, technically the microphone is not being captured again\n\n      stopRecording({\n        exportWAV: true,\n        wavCallback: blob => handleBlobToBase64({\n          blob,\n          continuous: continuous || false\n        })\n      });\n    });\n    setIsRecording(true);\n  };\n\n  const stopSpeechToText = () => {\n    if (recognition && !useOnlyGoogleCloud) {\n      recognition.stop();\n    } else {\n      var _mediaStream$current2;\n\n      setIsRecording(false);\n      (_mediaStream$current2 = mediaStream.current) === null || _mediaStream$current2 === void 0 ? void 0 : _mediaStream$current2.getAudioTracks()[0].stop();\n      stopRecording({\n        exportWAV: true,\n        wavCallback: blob => handleBlobToBase64({\n          blob,\n          continuous: false\n        })\n      });\n    }\n  };\n\n  const handleRecordingTimeout = () => {\n    timeoutId.current = window.setTimeout(() => {\n      var _mediaStream$current3;\n\n      setIsRecording(false);\n      (_mediaStream$current3 = mediaStream.current) === null || _mediaStream$current3 === void 0 ? void 0 : _mediaStream$current3.getAudioTracks()[0].stop();\n      stopRecording({\n        exportWAV: false\n      });\n    }, timeout);\n  };\n\n  const handleBlobToBase64 = ({\n    blob,\n    continuous\n  }) => {\n    const reader = new FileReader();\n    reader.readAsDataURL(blob);\n\n    reader.onloadend = async () => {\n      var _audioContextRef$curr3, _googleCloudJson$resu;\n\n      const base64data = reader.result;\n      let sampleRate = (_audioContextRef$curr3 = audioContextRef.current) === null || _audioContextRef$curr3 === void 0 ? void 0 : _audioContextRef$curr3.sampleRate; // Google only accepts max 48000 sample rate: if\n      // greater recorder js will down-sample to 48000\n\n      if (sampleRate && sampleRate > 48000) {\n        sampleRate = 48000;\n      }\n\n      const audio = {\n        content: ''\n      };\n      const config = {\n        encoding: 'LINEAR16',\n        languageCode: 'ar-SA',\n        sampleRateHertz: sampleRate,\n        ...googleCloudRecognitionConfig\n      };\n      const data = {\n        config,\n        audio\n      }; // Gets raw base 64 string data\n\n      audio.content = base64data.substr(base64data.indexOf(',') + 1);\n      const googleCloudRes = await fetch(`https://speech.googleapis.com/v1/speech:recognize?key=${googleApiKey}`, {\n        method: 'POST',\n        body: JSON.stringify(data)\n      });\n      const googleCloudJson = await googleCloudRes.json(); // Update results state with transcribed text\n\n      if (((_googleCloudJson$resu = googleCloudJson.results) === null || _googleCloudJson$resu === void 0 ? void 0 : _googleCloudJson$resu.length) > 0) {\n        setResults(prevResults => [...prevResults, googleCloudJson.results[0].alternatives[0].transcript]);\n      }\n\n      if (continuous) {\n        startSpeechToText();\n      }\n    };\n  };\n\n  return {\n    error,\n    interimResult,\n    isRecording,\n    results,\n    startSpeechToText,\n    stopSpeechToText\n  };\n}\n\n_s(useSpeechToText, \"LVeEqW31oz23gunmv4MwgyALRiE=\");","map":{"version":3,"sources":["/Users/admin/Desktop/ghyb/src/Hooks/index.tsx"],"names":["useState","useEffect","useRef","Hark","startRecording","stopRecording","isEdgeChromium","navigator","userAgent","indexOf","AudioContext","window","webkitAudioContext","SpeechRecognition","webkitSpeechRecognition","recognition","brave","isBrave","then","bool","useSpeechToText","continuous","crossBrowser","googleApiKey","googleCloudRecognitionConfig","onStartSpeaking","onStoppedSpeaking","speechRecognitionProperties","timeout","useOnlyGoogleCloud","isRecording","setIsRecording","audioContextRef","results","setResults","interimResult","setInterimResult","error","setError","timeoutId","mediaStream","mediaDevices","getUserMedia","console","current","chromeSpeechRecognition","grammars","interimResults","lang","maxAlternatives","start","onresult","e","result","length","transcript","isFinal","undefined","prevResults","concatTranscripts","i","resultIndex","onaudiostart","onend","startSpeechToText","state","resume","stream","errHandler","audioContext","handleRecordingTimeout","getAudioTracks","stop","clone","speechEvents","on","clearTimeout","exportWAV","wavCallback","blob","handleBlobToBase64","stopSpeechToText","setTimeout","reader","FileReader","readAsDataURL","onloadend","base64data","sampleRate","audio","content","config","encoding","languageCode","sampleRateHertz","data","substr","googleCloudRes","fetch","method","body","JSON","stringify","googleCloudJson","json","alternatives"],"mappings":";;AAAA,SAASA,QAAT,EAAmBC,SAAnB,EAA8BC,MAA9B,QAA4C,OAA5C;AACA,OAAOC,IAAP,MAAiB,MAAjB;AACA,SAASC,cAAT,EAAyBC,aAAzB,QAA8C,mBAA9C,C,CAEA;;AAYA,MAAMC,cAAc,GAAGC,SAAS,CAACC,SAAV,CAAoBC,OAApB,CAA4B,MAA5B,MAAwC,CAAC,CAAhE;AAQA,MAAMC,YAAY,GAAGC,MAAM,CAACD,YAAP,IAAwBC,MAAD,CAAgBC,kBAA5D;AAEA,MAAMC,iBAAiB,GACrBF,MAAM,CAACE,iBAAP,IAA6BF,MAAD,CAAgBG,uBAD9C;AAGA,IAAIC,WAAJ,C,CAEA;AACA;;AACA,IAAKR,SAAD,CAA8BS,KAAlC,EAAyC;AACtCT,EAAAA,SAAD,CAA8BS,KAA9B,CAAoCC,OAApC,GAA8CC,IAA9C,CAAoDC,IAAD,IAAU;AAC3D,QAAIA,IAAJ,EAAUJ,WAAW,GAAG,IAAd;AACX,GAFD;AAGD,C,CAED;AACA;AACA;;;AACA,IAAI,CAACT,cAAD,IAAmBO,iBAAvB,EAA0C;AACxCE,EAAAA,WAAW,GAAG,IAAIF,iBAAJ,EAAd;AACD;;AAcD,eAAe,SAASO,eAAT,CAAyB;AACtCC,EAAAA,UADsC;AAEtCC,EAAAA,YAFsC;AAGtCC,EAAAA,YAHsC;AAItCC,EAAAA,4BAJsC;AAKtCC,EAAAA,eALsC;AAMtCC,EAAAA,iBANsC;AAOtCC,EAAAA,2BAPsC;AAQtCC,EAAAA,OARsC;AAStCC,EAAAA,kBAAkB,GAAG;AATiB,CAAzB,EAUU;AAAA;;AACvB,QAAM,CAACC,WAAD,EAAcC,cAAd,IAAgC/B,QAAQ,CAAC,KAAD,CAA9C;AAEA,QAAMgC,eAAe,GAAG9B,MAAM,EAA9B;AAEA,QAAM,CAAC+B,OAAD,EAAUC,UAAV,IAAwBlC,QAAQ,CAAW,EAAX,CAAtC;AACA,QAAM,CAACmC,aAAD,EAAgBC,gBAAhB,IAAoCpC,QAAQ,EAAlD;AACA,QAAM,CAACqC,KAAD,EAAQC,QAAR,IAAoBtC,QAAQ,CAAC,EAAD,CAAlC;AAEA,QAAMuC,SAAS,GAAGrC,MAAM,EAAxB;AACA,QAAMsC,WAAW,GAAGtC,MAAM,EAA1B;AAEAD,EAAAA,SAAS,CAAC,MAAM;AAAA;;AACd,QAAI,CAACqB,YAAD,IAAiB,CAACP,WAAtB,EAAmC;AACjCuB,MAAAA,QAAQ,CAAC,oDAAD,CAAR;AACD;;AAED,QAAI,gBAAC/B,SAAD,wEAAC,WAAWkC,YAAZ,0DAAC,sBAAyBC,YAA1B,CAAJ,EAA4C;AAC1CJ,MAAAA,QAAQ,CAAC,yDAAD,CAAR;AACD;;AAED,QAAI,CAAChB,YAAY,IAAIO,kBAAjB,KAAwC,CAACN,YAA7C,EAA2D;AACzDoB,MAAAA,OAAO,CAACN,KAAR,CACE,mFADF;AAGD;;AAED,QAAI,CAACL,eAAe,CAACY,OAArB,EAA8B;AAC5BZ,MAAAA,eAAe,CAACY,OAAhB,GAA0B,IAAIlC,YAAJ,EAA1B;AACD;AACF,GAlBQ,EAkBN,EAlBM,CAAT,CAZuB,CAgCvB;AACA;;AACA,QAAMmC,uBAAuB,GAAG,MAAM;AACpC,QAAI9B,WAAJ,EAAiB;AACf;AACA,UAAIM,UAAJ,EAAgBN,WAAW,CAACM,UAAZ,GAAyB,IAAzB;AAEhB,YAAM;AAAEyB,QAAAA,QAAF;AAAYC,QAAAA,cAAZ;AAA4BC,QAAAA,IAA5B;AAAkCC,QAAAA;AAAlC,UACJtB,2BAA2B,IAAI,EADjC;AAGA,UAAImB,QAAJ,EAAc/B,WAAW,CAAC+B,QAAZ,GAAuBA,QAAvB;AACd,UAAIE,IAAJ,EAAUjC,WAAW,CAACiC,IAAZ,GAAmBA,IAAnB;AAEVjC,MAAAA,WAAW,CAACgC,cAAZ,GAA6BA,cAAc,IAAI,KAA/C;AACAhC,MAAAA,WAAW,CAACkC,eAAZ,GAA8BA,eAAe,IAAI,CAAjD,CAXe,CAaf;;AACAlC,MAAAA,WAAW,CAACmC,KAAZ,GAde,CAgBf;;AACAnC,MAAAA,WAAW,CAACoC,QAAZ,GAAwBC,CAAD,IAAO;AAC5B,cAAMC,MAAM,GAAGD,CAAC,CAACnB,OAAF,CAAUmB,CAAC,CAACnB,OAAF,CAAUqB,MAAV,GAAmB,CAA7B,CAAf;AACA,cAAM;AAAEC,UAAAA;AAAF,YAAiBF,MAAM,CAAC,CAAD,CAA7B,CAF4B,CAI5B;;AACA,YAAIN,cAAJ,EAAoB;AAClB,cAAIM,MAAM,CAACG,OAAX,EAAoB;AAClBpB,YAAAA,gBAAgB,CAACqB,SAAD,CAAhB;AACAvB,YAAAA,UAAU,CAAEwB,WAAD,IAAiB,CAAC,GAAGA,WAAJ,EAAiBH,UAAjB,CAAlB,CAAV;AACD,WAHD,MAGO;AACL,gBAAII,iBAAiB,GAAG,EAAxB,CADK,CAGL;;AACA,iBAAK,IAAIC,CAAC,GAAGR,CAAC,CAACS,WAAf,EAA4BD,CAAC,GAAGR,CAAC,CAACnB,OAAF,CAAUqB,MAA1C,EAAkDM,CAAC,EAAnD,EAAuD;AACrDD,cAAAA,iBAAiB,IAAIP,CAAC,CAACnB,OAAF,CAAU2B,CAAV,EAAa,CAAb,EAAgBL,UAArC;AACD;;AAEDnB,YAAAA,gBAAgB,CAACuB,iBAAD,CAAhB;AACD;AACF,SAdD,MAcO;AACLzB,UAAAA,UAAU,CAAEwB,WAAD,IAAiB,CAAC,GAAGA,WAAJ,EAAiBH,UAAjB,CAAlB,CAAV;AACD;AACF,OAtBD;;AAwBAxC,MAAAA,WAAW,CAAC+C,YAAZ,GAA2B,MAAM/B,cAAc,CAAC,IAAD,CAA/C,CAzCe,CA2Cf;AACA;;;AACAhB,MAAAA,WAAW,CAACgD,KAAZ,GAAoB,MAAM;AACxBhC,QAAAA,cAAc,CAAC,KAAD,CAAd;AACD,OAFD;AAGD;AACF,GAlDD;;AAoDA,QAAMiC,iBAAiB,GAAG,YAAY;AAAA;;AACpC,QAAI,CAACnC,kBAAD,IAAuBd,WAA3B,EAAwC;AACtC8B,MAAAA,uBAAuB;AACvB;AACD;;AAED,QAAI,CAACvB,YAAD,IAAiB,CAACO,kBAAtB,EAA0C;AACxC;AACD,KARmC,CAUpC;AACA;;;AACA,QAAI,0BAAAG,eAAe,CAACY,OAAhB,gFAAyBqB,KAAzB,MAAmC,WAAvC,EAAoD;AAAA;;AAClD,gCAAAjC,eAAe,CAACY,OAAhB,kFAAyBsB,MAAzB;AACD;;AAED,UAAMC,MAAM,GAAG,MAAM/D,cAAc,CAAC;AAClCgE,MAAAA,UAAU,EAAE,MAAM9B,QAAQ,CAAC,kCAAD,CADQ;AAElC+B,MAAAA,YAAY,EAAErC,eAAe,CAACY;AAFI,KAAD,CAAnC,CAhBoC,CAqBpC;;AACA,QAAIhB,OAAJ,EAAa;AACX0C,MAAAA,sBAAsB;AACvB,KAxBmC,CA0BpC;;;AACA,QAAI9B,WAAW,CAACI,OAAhB,EAAyB;AACvBJ,MAAAA,WAAW,CAACI,OAAZ,CAAoB2B,cAApB,GAAqC,CAArC,EAAwCC,IAAxC;AACD,KA7BmC,CA+BpC;;;AACAhC,IAAAA,WAAW,CAACI,OAAZ,GAAsBuB,MAAM,CAACM,KAAP,EAAtB;AAEA,UAAMC,YAAY,GAAGvE,IAAI,CAACqC,WAAW,CAACI,OAAb,EAAsB;AAC7CyB,MAAAA,YAAY,EAAErC,eAAe,CAACY;AADe,KAAtB,CAAzB;AAIA8B,IAAAA,YAAY,CAACC,EAAb,CAAgB,UAAhB,EAA4B,MAAM;AAChC,UAAIlD,eAAJ,EAAqBA,eAAe,GADJ,CAGhC;;AACAmD,MAAAA,YAAY,CAACrC,SAAS,CAACK,OAAX,CAAZ;AACD,KALD;AAOA8B,IAAAA,YAAY,CAACC,EAAb,CAAgB,kBAAhB,EAAoC,MAAM;AAAA;;AACxC,UAAIjD,iBAAJ,EAAuBA,iBAAiB;AAExCK,MAAAA,cAAc,CAAC,KAAD,CAAd;AACA,8BAAAS,WAAW,CAACI,OAAZ,8EAAqB2B,cAArB,GAAsC,CAAtC,EAAyCC,IAAzC,GAJwC,CAMxC;AACA;AACA;AACA;;AACAnE,MAAAA,aAAa,CAAC;AACZwE,QAAAA,SAAS,EAAE,IADC;AAEZC,QAAAA,WAAW,EAAGC,IAAD,IACXC,kBAAkB,CAAC;AAAED,UAAAA,IAAF;AAAQ1D,UAAAA,UAAU,EAAEA,UAAU,IAAI;AAAlC,SAAD;AAHR,OAAD,CAAb;AAKD,KAfD;AAiBAU,IAAAA,cAAc,CAAC,IAAD,CAAd;AACD,GA/DD;;AAiEA,QAAMkD,gBAAgB,GAAG,MAAM;AAC7B,QAAIlE,WAAW,IAAI,CAACc,kBAApB,EAAwC;AACtCd,MAAAA,WAAW,CAACyD,IAAZ;AACD,KAFD,MAEO;AAAA;;AACLzC,MAAAA,cAAc,CAAC,KAAD,CAAd;AACA,+BAAAS,WAAW,CAACI,OAAZ,gFAAqB2B,cAArB,GAAsC,CAAtC,EAAyCC,IAAzC;AACAnE,MAAAA,aAAa,CAAC;AACZwE,QAAAA,SAAS,EAAE,IADC;AAEZC,QAAAA,WAAW,EAAGC,IAAD,IAAUC,kBAAkB,CAAC;AAAED,UAAAA,IAAF;AAAQ1D,UAAAA,UAAU,EAAE;AAApB,SAAD;AAF7B,OAAD,CAAb;AAID;AACF,GAXD;;AAaA,QAAMiD,sBAAsB,GAAG,MAAM;AACnC/B,IAAAA,SAAS,CAACK,OAAV,GAAoBjC,MAAM,CAACuE,UAAP,CAAkB,MAAM;AAAA;;AAC1CnD,MAAAA,cAAc,CAAC,KAAD,CAAd;AACA,+BAAAS,WAAW,CAACI,OAAZ,gFAAqB2B,cAArB,GAAsC,CAAtC,EAAyCC,IAAzC;AACAnE,MAAAA,aAAa,CAAC;AAAEwE,QAAAA,SAAS,EAAE;AAAb,OAAD,CAAb;AACD,KAJmB,EAIjBjD,OAJiB,CAApB;AAKD,GAND;;AAQA,QAAMoD,kBAAkB,GAAG,CAAC;AAC1BD,IAAAA,IAD0B;AAE1B1D,IAAAA;AAF0B,GAAD,KAMrB;AACJ,UAAM8D,MAAM,GAAG,IAAIC,UAAJ,EAAf;AACAD,IAAAA,MAAM,CAACE,aAAP,CAAqBN,IAArB;;AAEAI,IAAAA,MAAM,CAACG,SAAP,GAAmB,YAAY;AAAA;;AAC7B,YAAMC,UAAU,GAAGJ,MAAM,CAAC9B,MAA1B;AAEA,UAAImC,UAAU,6BAAGxD,eAAe,CAACY,OAAnB,2DAAG,uBAAyB4C,UAA1C,CAH6B,CAK7B;AACA;;AACA,UAAIA,UAAU,IAAIA,UAAU,GAAG,KAA/B,EAAsC;AACpCA,QAAAA,UAAU,GAAG,KAAb;AACD;;AAED,YAAMC,KAAK,GAAG;AAAEC,QAAAA,OAAO,EAAE;AAAX,OAAd;AAEA,YAAMC,MAAoC,GAAG;AAC3CC,QAAAA,QAAQ,EAAE,UADiC;AAE3CC,QAAAA,YAAY,EAAE,OAF6B;AAG3CC,QAAAA,eAAe,EAAEN,UAH0B;AAI3C,WAAGhE;AAJwC,OAA7C;AAOA,YAAMuE,IAAI,GAAG;AACXJ,QAAAA,MADW;AAEXF,QAAAA;AAFW,OAAb,CApB6B,CAyB7B;;AACAA,MAAAA,KAAK,CAACC,OAAN,GAAgBH,UAAU,CAACS,MAAX,CAAkBT,UAAU,CAAC9E,OAAX,CAAmB,GAAnB,IAA0B,CAA5C,CAAhB;AAEA,YAAMwF,cAAc,GAAG,MAAMC,KAAK,CAC/B,yDAAwD3E,YAAa,EADtC,EAEhC;AACE4E,QAAAA,MAAM,EAAE,MADV;AAEEC,QAAAA,IAAI,EAAEC,IAAI,CAACC,SAAL,CAAeP,IAAf;AAFR,OAFgC,CAAlC;AAQA,YAAMQ,eAAe,GAAG,MAAMN,cAAc,CAACO,IAAf,EAA9B,CApC6B,CAsC7B;;AACA,UAAI,0BAAAD,eAAe,CAACtE,OAAhB,gFAAyBqB,MAAzB,IAAkC,CAAtC,EAAyC;AACvCpB,QAAAA,UAAU,CAAEwB,WAAD,IAAiB,CAC1B,GAAGA,WADuB,EAE1B6C,eAAe,CAACtE,OAAhB,CAAwB,CAAxB,EAA2BwE,YAA3B,CAAwC,CAAxC,EAA2ClD,UAFjB,CAAlB,CAAV;AAID;;AAED,UAAIlC,UAAJ,EAAgB;AACd2C,QAAAA,iBAAiB;AAClB;AACF,KAjDD;AAkDD,GA5DD;;AA8DA,SAAO;AACL3B,IAAAA,KADK;AAELF,IAAAA,aAFK;AAGLL,IAAAA,WAHK;AAILG,IAAAA,OAJK;AAKL+B,IAAAA,iBALK;AAMLiB,IAAAA;AANK,GAAP;AAQD;;GA5PuB7D,e","sourcesContent":["import { useState, useEffect, useRef } from 'react';\nimport Hark from 'hark';\nimport { startRecording, stopRecording } from './recorderHelpers';\n\n// https://cloud.google.com/speech-to-text/docs/reference/rest/v1/RecognitionConfig\nimport { GoogleCloudRecognitionConfig } from './GoogleCloudRecognitionConfig';\n\n// https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition\nexport interface SpeechRecognitionProperties {\n  // continuous: do not pass continuous here, instead pass it as a param to the hook\n  grammars?: SpeechGrammarList;\n  interimResults?: boolean;\n  lang?: string;\n  maxAlternatives?: number;\n}\n\nconst isEdgeChromium = navigator.userAgent.indexOf('Edg/') !== -1;\n\ninterface BraveNavigator extends Navigator {\n  brave: {\n    isBrave: () => Promise<boolean>;\n  };\n}\n\nconst AudioContext = window.AudioContext || (window as any).webkitAudioContext;\n\nconst SpeechRecognition =\n  window.SpeechRecognition || (window as any).webkitSpeechRecognition;\n\nlet recognition: SpeechRecognition | null;\n\n// Set recognition back to null for brave browser due to promise resolving\n// after the conditional on line 31\nif ((navigator as BraveNavigator).brave) {\n  (navigator as BraveNavigator).brave.isBrave().then((bool) => {\n    if (bool) recognition = null;\n  });\n}\n\n// Chromium browsers will have the SpeechRecognition method\n// but do not implement the functionality due to google wanting ðŸ’°\n// this covers new Edge and line 22 covers Brave, the two most popular non-chrome chromium browsers\nif (!isEdgeChromium && SpeechRecognition) {\n  recognition = new SpeechRecognition();\n}\n\nexport interface UseSpeechToTextTypes {\n  continuous?: boolean;\n  crossBrowser?: boolean;\n  googleApiKey?: string;\n  googleCloudRecognitionConfig?: GoogleCloudRecognitionConfig;\n  onStartSpeaking?: () => any;\n  onStoppedSpeaking?: () => any;\n  speechRecognitionProperties?: SpeechRecognitionProperties;\n  timeout?: number;\n  useOnlyGoogleCloud?: boolean;\n}\n\nexport default function useSpeechToText({\n  continuous,\n  crossBrowser,\n  googleApiKey,\n  googleCloudRecognitionConfig,\n  onStartSpeaking,\n  onStoppedSpeaking,\n  speechRecognitionProperties,\n  timeout,\n  useOnlyGoogleCloud = true\n}: UseSpeechToTextTypes) {\n  const [isRecording, setIsRecording] = useState(false);\n\n  const audioContextRef = useRef<AudioContext>();\n\n  const [results, setResults] = useState<string[]>([]);\n  const [interimResult, setInterimResult] = useState<string | undefined>();\n  const [error, setError] = useState('');\n\n  const timeoutId = useRef<number>();\n  const mediaStream = useRef<MediaStream>();\n\n  useEffect(() => {\n    if (!crossBrowser && !recognition) {\n      setError('Speech Recognition API is only available on Chrome');\n    }\n\n    if (!navigator?.mediaDevices?.getUserMedia) {\n      setError('getUserMedia is not supported on this device/browser :(');\n    }\n\n    if ((crossBrowser || useOnlyGoogleCloud) && !googleApiKey) {\n      console.error(\n        'No google cloud API key was passed, google API will not be able to process speech'\n      );\n    }\n\n    if (!audioContextRef.current) {\n      audioContextRef.current = new AudioContext();\n    }\n  }, []);\n\n  // Chrome Speech Recognition API:\n  // Only supported on Chrome browsers\n  const chromeSpeechRecognition = () => {\n    if (recognition) {\n      // Continuous recording after stopped speaking event\n      if (continuous) recognition.continuous = true;\n\n      const { grammars, interimResults, lang, maxAlternatives } =\n        speechRecognitionProperties || {};\n\n      if (grammars) recognition.grammars = grammars;\n      if (lang) recognition.lang = lang;\n\n      recognition.interimResults = interimResults || false;\n      recognition.maxAlternatives = maxAlternatives || 1;\n\n      // start recognition\n      recognition.start();\n\n      // speech successfully translated into text\n      recognition.onresult = (e) => {\n        const result = e.results[e.results.length - 1];\n        const { transcript } = result[0];\n\n        // Allows for realtime speech result UI feedback\n        if (interimResults) {\n          if (result.isFinal) {\n            setInterimResult(undefined);\n            setResults((prevResults) => [...prevResults, transcript]);\n          } else {\n            let concatTranscripts = '';\n\n            // If continuous: e.results will include previous speech results: need to start loop at the current event resultIndex for proper concatenation\n            for (let i = e.resultIndex; i < e.results.length; i++) {\n              concatTranscripts += e.results[i][0].transcript;\n            }\n\n            setInterimResult(concatTranscripts);\n          }\n        } else {\n          setResults((prevResults) => [...prevResults, transcript]);\n        }\n      };\n\n      recognition.onaudiostart = () => setIsRecording(true);\n\n      // Audio stopped recording or timed out.\n      // Chrome speech auto times-out if no speech after a while\n      recognition.onend = () => {\n        setIsRecording(false);\n      };\n    }\n  };\n\n  const startSpeechToText = async () => {\n    if (!useOnlyGoogleCloud && recognition) {\n      chromeSpeechRecognition();\n      return;\n    }\n\n    if (!crossBrowser && !useOnlyGoogleCloud) {\n      return;\n    }\n\n    // Resume audio context due to google auto play policy\n    // https://developers.google.com/web/updates/2017/09/autoplay-policy-changes#webaudio\n    if (audioContextRef.current?.state === 'suspended') {\n      audioContextRef.current?.resume();\n    }\n\n    const stream = await startRecording({\n      errHandler: () => setError('Microphone permission was denied'),\n      audioContext: audioContextRef.current as AudioContext\n    });\n\n    // Stop recording if timeout\n    if (timeout) {\n      handleRecordingTimeout();\n    }\n\n    // stop previous mediaStream track if exists\n    if (mediaStream.current) {\n      mediaStream.current.getAudioTracks()[0].stop();\n    }\n\n    // Clones stream to fix hark bug on Safari\n    mediaStream.current = stream.clone();\n\n    const speechEvents = Hark(mediaStream.current, {\n      audioContext: audioContextRef.current as AudioContext\n    });\n\n    speechEvents.on('speaking', () => {\n      if (onStartSpeaking) onStartSpeaking();\n\n      // Clear previous recording timeout on every speech event\n      clearTimeout(timeoutId.current);\n    });\n\n    speechEvents.on('stopped_speaking', () => {\n      if (onStoppedSpeaking) onStoppedSpeaking();\n\n      setIsRecording(false);\n      mediaStream.current?.getAudioTracks()[0].stop();\n\n      // Stops current recording and sends audio string to google cloud.\n      // recording will start again after google cloud api\n      // call if `continuous` prop is true. Until the api result\n      // returns, technically the microphone is not being captured again\n      stopRecording({\n        exportWAV: true,\n        wavCallback: (blob) =>\n          handleBlobToBase64({ blob, continuous: continuous || false })\n      });\n    });\n\n    setIsRecording(true);\n  };\n\n  const stopSpeechToText = () => {\n    if (recognition && !useOnlyGoogleCloud) {\n      recognition.stop();\n    } else {\n      setIsRecording(false);\n      mediaStream.current?.getAudioTracks()[0].stop();\n      stopRecording({\n        exportWAV: true,\n        wavCallback: (blob) => handleBlobToBase64({ blob, continuous: false })\n      });\n    }\n  };\n\n  const handleRecordingTimeout = () => {\n    timeoutId.current = window.setTimeout(() => {\n      setIsRecording(false);\n      mediaStream.current?.getAudioTracks()[0].stop();\n      stopRecording({ exportWAV: false });\n    }, timeout);\n  };\n\n  const handleBlobToBase64 = ({\n    blob,\n    continuous\n  }: {\n    blob: Blob;\n    continuous: boolean;\n  }) => {\n    const reader = new FileReader();\n    reader.readAsDataURL(blob);\n\n    reader.onloadend = async () => {\n      const base64data = reader.result as string;\n\n      let sampleRate = audioContextRef.current?.sampleRate;\n\n      // Google only accepts max 48000 sample rate: if\n      // greater recorder js will down-sample to 48000\n      if (sampleRate && sampleRate > 48000) {\n        sampleRate = 48000;\n      }\n\n      const audio = { content: '' };\n\n      const config: GoogleCloudRecognitionConfig = {\n        encoding: 'LINEAR16',\n        languageCode: 'ar-SA',\n        sampleRateHertz: sampleRate,\n        ...googleCloudRecognitionConfig\n      };\n\n      const data = {\n        config,\n        audio\n      };\n\n      // Gets raw base 64 string data\n      audio.content = base64data.substr(base64data.indexOf(',') + 1);\n\n      const googleCloudRes = await fetch(\n        `https://speech.googleapis.com/v1/speech:recognize?key=${googleApiKey}`,\n        {\n          method: 'POST',\n          body: JSON.stringify(data)\n        }\n      );\n\n      const googleCloudJson = await googleCloudRes.json();\n\n      // Update results state with transcribed text\n      if (googleCloudJson.results?.length > 0) {\n        setResults((prevResults) => [\n          ...prevResults,\n          googleCloudJson.results[0].alternatives[0].transcript\n        ]);\n      }\n\n      if (continuous) {\n        startSpeechToText();\n      }\n    };\n  };\n\n  return {\n    error,\n    interimResult,\n    isRecording,\n    results,\n    startSpeechToText,\n    stopSpeechToText\n  };\n}\n"]},"metadata":{},"sourceType":"module"}